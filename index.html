<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MedCalc-Bench: Dataset for evaluating LLMs on medical calculations</title>

  <div style="margin-top: 30px;"></div>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
 
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MedCalc-Bench: Evaluating Large Language Models for Medical Calculations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Nikhil Khandekar<sup>1,4*</sup>,</span>
            <span class="author-block">Qiao Jin<sup>1*</sup>,</span>
            <span class="author-block">Guangzhi Xiong<sup>2*</sup>,</span>
            <span class="author-block">Soren Dunn<sup>3,4</sup>,</span>
            <span class="author-block">Serina S Applebaum<sup>5</sup>,</span>
            <span class="author-block">Zain Anwar<sup>7</sup>,</span>
            <span class="author-block">Maame Sarfo-Gyamfi<sup>8</sup>,</span>
            <span class="author-block">Conrad W Safranek<sup>5</sup>,</span>
            <span class="author-block">Abid A Anwar<sup>6</sup>,</span>
            <span class="author-block">Andrew Zhang<sup>9</sup>,</span>
            <span class="author-block">Aidan Gilson<sup>5</sup>,</span>
            <span class="author-block">Maxwell B Singer<sup>5</sup>,</span>
            <span class="author-block">Amisha Dave<sup>5</sup>,</span>
            <span class="author-block">Andrew Taylor<sup>5</sup>,</span>
            <span class="author-block">Aidong Zhang<sup>2</sup>,</span>
            <span class="author-block">Qingyu Chen<sup>5</sup>,</span>
            <span class="author-block">Zhiyong Lu<sup>1†</sup></span>
          </div>

          <!-- Add spacing between authors and institutions -->
          <div style="margin-top: 30px;"></div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Library of Medicine, National Institutes of Health,</span>
            <span class="author-block"><sup>2</sup>University of Virginia,</span>
            <span class="author-block"><sup>3</sup>University of Illinois at Urbana Champaign,</span>
            <span class="author-block"><sup>4</sup>Lapis Labs,</span>
            <span class="author-block"><sup>5</sup>Yale University School of Medicine,</span>
            <span class="author-block"><sup>6</sup>University of Illinois College of Medicine at Chicago,</span>
            <span class="author-block"><sup>7</sup>Rosalind Franklin University Chicago Medical School,</span>
            <span class="author-block"><sup>8</sup>Howard University College of Medicine,</span>
            <span class="author-block"><sup>9</sup>University of Chicago Pritzker School of Medicine</span>
          </div>

          <!-- Add corresponding author and equal contribution note -->
          <div style="margin-top: 30px;">
            <p class="is-size-6">* Equal contribution</p>
            <p class="is-size-6">† Correspondence to zhiyong.lu@nih.gov</p>
          </div>

          <div style="margin-top: 30px;"></div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.12036"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.12036"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link -->
              <span class="link-block">
                <a href="https://recorder-v3.slideslive.com/?share=93853&s=af5f56bc-5865-47d0-8f8c-9a11e3547c6f"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/ncbi-nlp/MedCalc-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Dataset Link -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/ncbi/MedCalc-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section"></section>
  <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <div class="content has-text-centered">
          <img src="./static/css/images/instance_illustration.png" alt="Overview of MedCalc-Bench" width="84%"/>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            As opposed to evaluating computation and logic-based reasoning, current benchmarks for evaluating large language models (LLMs) in medicine are primarily
            focused on question-answering involving domain knowledge and descriptive reasoning. While such qualitative capabilities are vital to medical diagnosis, in realworld scenarios, doctors frequently use clinical calculators that follow quantitative
            equations and rule-based reasoning paradigms for evidence-based decision support.
            To this end, we propose MEDCALC-BENCH, a first-of-its-kind dataset focused
            on evaluating the medical calculation capability of LLMs. MEDCALC-BENCH
            contains an evaluation set of over 1000 manually reviewed instances from 55 different medical calculation tasks. Each instance in MEDCALC-BENCH consists of a
            patient note, a question requesting to compute a specific medical value, a ground
            truth answer, and a step-by-step explanation showing how the answer is obtained.
            While our evaluation results show the potential of LLMs in this area, none of them
            are effective enough for clinical settings. Common issues include extracting the
            incorrect entities, not using the correct equation or rules for a calculation task,
            or incorrectly performing the arithmetic for the computation. We hope our study
            highlights the quantitative knowledge and reasoning gaps in LLMs within medical
            settings, encouraging future improvements of LLMs for various clinical calculation
            tasks.            
          </p>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Overview</h2>
        <div class="content has-text-justified">
          <p>
            MEDCALC-BENCH covers 55 different calculators. These were all listed as "popular" on MDCalc,
            the most commonly used online medical calculator website by clinicians [9]. As shown in Figure
            1, they fall into two major categories, rule-based calculation (19 calculators) and equation-based
            calculation (36 calculators). Rule-based calculators typically contain a list of criteria, where each criterion is a condition of a
            specific medical attribute. An instance of this would be the HEART score calculator [43], which takes
            in both numerical attributes such as the patient’s age (e.g., if the patient is older than 65 years, add
            two points; if the patient’s age is between 45 and 64, add one point; and zero points otherwise) and
            categorical variables such as the presence of significant ST elevation (adding two points if present;
            zero points otherwise). The final answer for these calculators will be a discrete value after taking the
            sum of the sub-scores.Like rule-based calculators, equation-based calculators also take in both categorical (e.g., gender, race)
            and numerical variables (e.g., creatinine concentration, age, and height). However, equation-based
            calculators follow a specific formula to output a decimal, date, or time given the attributes instead of
            additively combining sub-scores for each criterion. An instance of an equation-based calculator would
            be the MDRD GRF equation [26]. This equation computes the patient’s eGFR, which is a function
            of the patient’s gender and race as coefficients in addition to the patient’s creatinine concentration.
            The only equation-based calculators which do not output a decimal are Estimated Due Date (EDD),
            Estimated Date of Conception (EDC), and Estimated Gestational Age (EGA). These three calculators
            compute a date (for EDC, EGA) or a time (for EGA) instead.For each instance, MEDCALC-BENCH also provides a natural language explanation for how the
            final answer is computed. We implement template-based explanation generators for each of the 55
            calculators. These templates first list the numerical and categorical variable values, and then plug
            them in to show how the final answers are obtained. 
          </p>

          <p>
            (1) Recall of medical calculation knowledge. The first required capability is to successfully recall
            the formulas from seven different domains shown in Table 1. As mentioned above, medical calculators
            can have various sub-types with varying number of attributes. Hence, LLMs are challenged to know
            every detail about medical equations or rules to solve a question in MEDCALC-BENCH.
            (2) Extraction of relevant patient attributes. The second required capability is the extraction
            of correct attributes from patient notes, given the noises in the long context of over 500 words
            on average. LLMs are required to extract both numerical and categorical attributes. The medical
            context complicates such extractions, with the existence of multiple synonyms (e.g., both HbA1c and
            glycohemoglobin denote the same entity) and the requirement of determining the presence of certain
            medical cases without explicitly being stated (e.g., a blood pressure of 160/100 mmHg indicates the
            presence of hypertension). Hence, LLMs require both medical knowledge and clinical reasoning to
            solve questions in this dataset.(3) Arithmetic computation of the final results. The third required capability is the computation
            of final results, especially the derivation of scores through multi-step reasoning. While datasets like
            GSM-8k have tested the arithmetic calculation capability of LLMs, MEDCALC-BENCH presents a
            more challenging task. Our dataset requires LLMs to fully understand the sequence and dependencies
            among multiple medical equations or rules, some of which need to be chained together, to obtain the
            correct answer. Additionally, MEDCALC-BENCH also contains some exponential computations that
            are not covered by other math datasets
          </p>>
        </div>
      </div>
    </div>
</section>






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{khandekar2024medcalcbenchevaluatinglargelanguage,
      title={MedCalc-Bench: Evaluating Large Language Models for Medical Calculations}, 
      author={Nikhil Khandekar and Qiao Jin and Guangzhi Xiong and Soren Dunn and Serina S Applebaum and Zain Anwar and Maame Sarfo-Gyamfi and Conrad W Safranek and Abid A Anwar and Andrew Zhang and Aidan Gilson and Maxwell B Singer and Amisha Dave and Andrew Taylor and Aidong Zhang and Qingyu Chen and Zhiyong Lu},
      year={2024},
      eprint={2406.12036},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12036}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2406.12036">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/nikhilk7153" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from Nerfies <a rel="webpage" href="https://nerfies.github.io/">Nerfies</a> and <a rel="webpage" href="https://mathvista.github.io/">MathVista</a>, licensed under the  a <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
